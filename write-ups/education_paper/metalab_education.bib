%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Page Piccinini at 2016-07-27 11:41:26 +0200 


%% Saved with string encoding Unicode (UTF-8) 

@article{button2013power,
  title={Power failure: why small sample size undermines the reliability of neuroscience},
  author={Button, Katherine S and Ioannidis, John PA and Mokrysz, Claire and Nosek, Brian A and Flint, Jonathan and Robinson, Emma SJ and Munaf{\`o}, Marcus R},
  journal={Nature Reviews Neuroscience},
  volume={14},
  number={5},
  pages={365--376},
  year={2013},
  publisher={Nature Publishing Group}
}

@article{ioannidis2005most,
  title={Why most published research findings are false},
  author={Ioannidis, John PA},
  journal={PLoS Med},
  volume={2},
  number={8},
  pages={e124},
  year={2005},
  publisher={Public Library of Science}
}

@article{Csibra, 
  title={Statistical treatment of looking-time data.},
  author={Csibra, Gergely and Hernik, Miko{\l}aj and Mascaro, Olivier and Tatone, Denis and Lengyel, M{\'a}t{\'e}},
  journal={Developmental psychology},
  volume={52},
  number={4},
  pages={521--536},
  year={2016},
  publisher={American Psychological Association}
}


@article{InWordDB, 
  title={Development of infants' segmentation of words from native speech: a meta-analytic approach},
  author={Bergmann, Christina and Cristia, Alejandrina},
  journal={Developmental science},
  year={2015},
  publisher={Wiley Online Library}
}

@article{InPhonDB, 
  title={Perceptual attunement in vowels: A meta-analysis},
  author={Tsuji, Sho and Cristia, Alejandrina},
  journal={Developmental psychobiology},
  volume={56},
  number={2},
  pages={179--191},
  year={2014},
  publisher={Wiley Online Library}
}

@misc{Manybabies,
author={Frank, M. C.},
date={2016, September 13},
title={{A collaborative approach to infant research: Promoting reproducibility, best practices, and theory-building}}, 
note={Retrieved from osf.io/27b43}
}



@article{Sterling1995,
	Author = {T. D. Sterling and W. L. Rosenbaum and J. J. Weinkam},
	Date-Added = {2016-07-27 09:40:42 +0000},
	Date-Modified = {2016-07-27 09:41:25 +0000},
	Journal = {The American Statistician},
	Number = {1},
	Pages = {108-112},
	Title = {Publication decisions revisited: The effect of the outcome of statistical tests on the decision to publish and vice versa},
	Volume = {49},
	Year = {1995}}

@article{Vanpaemel2015,
	Author = {W. Vanpaemel and M. Vermorgen and L. Deriemaecker and G. Storms},
	Date-Added = {2016-07-27 09:39:14 +0000},
	Date-Modified = {2016-07-27 09:40:11 +0000},
	Journal = {Collabra},
	Number = {1},
	Title = {Are we wasting a good crisis? The availability of psychological research data after the storm},
	Volume = {1},
	Year = {2015}}

@article{Loftus1996,
	Author = {G. R. Loftus},
	Date-Added = {2016-07-27 09:38:39 +0000},
	Date-Modified = {2016-07-27 09:39:08 +0000},
	Journal = {Current directions in psychological science},
	Number = {6},
	Pages = {161-171},
	Title = {Psychology will be a much better science when we change the way we analyze data},
	Volume = {5},
	Year = {1996}}

@article{Ellis2015,
	Author = {D. A. Ellis and H. L. Merdian},
	Date-Added = {2016-07-27 09:36:56 +0000},
	Date-Modified = {2016-07-27 09:38:38 +0000},
	Journal = {Frontiers in psychology},
	Pages = {1-6},
	Title = {Thinking outside the box: developing dynamic data visualizations for psychology with Shiny},
	Volume = {6},
	Year = {2015}}

@article{Tsuji2014,
	Author = {Sho Tsuji and Christina Bergmann and Alejandrina Cristia},
	Date-Added = {2016-07-27 09:32:47 +0000},
	Date-Modified = {2016-07-27 09:34:43 +0000},
	Journal = {Psychological Science},
	Number = {6},
	Pages = {661-665},
	Title = {Community-Augmented Meta-Analyses: Toward Cumulative Data Assessment},
	Volume = {9},
	Year = {2014}}

@article{Peterson2016,
	Author = {D. Peterson},
	Date-Added = {2016-07-27 09:29:40 +0000},
	Date-Modified = {2016-07-27 09:31:57 +0000},
	Journal = {Socius: Sociological Research for a Dynamic World},
	Pages = {1-10},
	Title = {The Baby Factory: Difficult Research Objects, Disciplinary Standards, and the Production of Statistical Significance},
	Volume = {2},
	Year = {2016}}

@article{Marszalek2011,
	Author = {J. M. Marszalek and C. Barber and J. Kohlhart and C. B. Holmes},
	Date-Added = {2016-07-27 09:27:34 +0000},
	Date-Modified = {2016-07-27 09:28:48 +0000},
	Journal = {Perceptual and motor skills},
	Number = {2},
	Pages = {331-348},
	Title = {Sample size in psychological research over the past 30 years 1, 2},
	Volume = {112},
	Year = {2011}}

@article{Mills-Smith2015,
	Author = {L. Mills-Smith and D. P. Spangler and R. Panneton and M. S. Fritz},
	Date-Added = {2016-07-27 09:25:12 +0000},
	Date-Modified = {2016-07-27 09:26:21 +0000},
	Journal = {Infancy},
	Number = {4},
	Pages = {416-432},
	Title = {A missed opportunity for clarity: Problems in the reporting of effect size estimates in infant developmental science},
	Volume = {20},
	Year = {2015}}

@manual{APA2001,
	Address = {Washington, DC},
	Author = {{American Psychological Association}},
	Date-Added = {2016-07-27 09:21:57 +0000},
	Date-Modified = {2016-07-27 09:24:04 +0000},
	Edition = {5th},
	Organization = {American Psychological Association},
	Title = {Publication manual of the American psychological association},
	Year = {2001}}

@article{John2012,
	Author = {Leslie K. John and George Loewenstein and Drazen Prelec},
	Date-Added = {2016-07-27 09:17:51 +0000},
	Date-Modified = {2016-07-27 09:19:27 +0000},
	Journal = {Psychological Science},
	Number = {5},
	Pages = {524-532},
	Title = {Measuring the prevalence of questionable research practices with incentives for truth telling},
	Volume = {23},
	Year = {2012}}

@article{Simmons2011,
	Author = {Joseph P. Simmons and Leif D. Nelson and Uri Simonsohn},
	Date-Added = {2016-07-27 09:13:58 +0000},
	Date-Modified = {2016-07-27 09:17:36 +0000},
	Journal = {Psychological Science},
	Number = {11},
	Pages = {1359-1366},
	Title = {False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant},
	Volume = {22},
	Year = {2011}}

@article{Dumas-Mallet2016,
	Abstract = {Context There are growing concerns about effect size inflation and replication validity of association studies, but few observational investigations have explored the extent of these problems. Objective Using meta-analyses to measure the reliability of initial studies and explore whether this var- ies across biomedical domains and study types (cognitive/behavioral, brain imaging, genetic and ``others''). Methods We analyzed 663 meta-analyses describing associations between markers or risk factors and 12 pathologies within three biomedical domains (psychiatry, neurology and four somatic diseases). We collected the effect size, sample size, publication year and Impact Factor of initial studies, largest studies (i.e., with the largest sample size) and the corre- sponding meta-analyses. Initial studies were considered as replicated if they were in nomi- nal agreement with meta-analyses and if their effect size inflation was below 100{\%}. Results Nominal agreement between initial studies and meta-analyses regarding the presence of a significant effect was not better than chance in psychiatry, whereas it was somewhat better in neurology and somatic diseases. Whereas effect sizes reported by largest studies and meta-analyses were similar, most of those reported by initial studies were inflated. Among the 256 initial studies reporting a significant effect (p{\textless}0.05) and paired with significant meta- analyses, 97 effect sizes were inflated by more than 100{\%}. Nominal agreement and effect size inflation varied with the biomedical domain and study type. Indeed, the replication rate of initial studies reporting a significant effect ranged from 6.3{\%} for genetic studies in psychi- atry to 86.4{\%} for cognitive/behavioral studies. Comparison between eight subgroups shows that replication rate decreases with sample size and ``true'' effect size. Weobserved no evi- dence of association between replication rate and publication year or Impact Factor. Conclusion The differences in reliability between biological psychiatry, neurology and somatic diseases suggest that there is room for improvement, at least in some subdomains.},
	Annote = {Article Number: 359

- lack of systematic analysis of preclinical, clinical, and association studies for replication problems
- current study: 1) sees how psychiatry and neurology compare for meta-analyses, and 2) how do these compare to somatic diseases

METHODS
SELECTION OF META-ANALYSES FOR INCLUSION
- look for all meta-analyses on PubMed between January 1, 2008 and December 31, 2012 (5 year period)
- had specific keywords for each dieases (diseases a sub part of each larger category outlined above)
- need at least 7 data sets from at least 4 independent publications
SELECTION OF INITIAL STUDIES AND LARGEST STUDIES
- 110 initial studies, add to data sets if missing
DATA EXTRACTION
- data collected from initial, larger meta-analysis: 1) year of publication, 2) first author, 3) 2012 Impact Factor of journal published in, 4) nominal statical significance (based on p-value), 5) effect size, 6) p-value, 7) number of patients and healthy controls, 7) number of data sets
- convert to Cohen's d
- convert to ln(OR), ln(OR) = d x pi/sqrt(3)
SENSITIVITY AND SPECIFICITY ANALYSIS
- ``sensitivity expresses the conditional probability that an initial study predicts a significant effect when a significant effect is actually confirmed by the corresponding meta-analysis'' (p. 4)
- ``Specificity expresses the probability that an initial study reporting a non-significant effect corresponds to a meta-analysis supporting the same view'' (p. 4)
- 2 x 2 of original result and meta analysis allows for: 1) sensitivity, 2) specificity, 3) false positive, 4) false negative
- false positive include when original has a sig effect and meta analysis has sig effect in other direction
DEFINING A SMALL EFFECT
- small effect d {\textless}= 0.51
- for studies with odds ratio small effect d {\textless}= 0.29
- genetic association studies small effect OR {\textless}= 1.11
- other split into two groups, d {\textless}= 0.30, OR {\textless}= 1.20
STATISTICAL ANALYSES
- ``Effect sizes of initial or largest studies were compared to those of the corresponding meta-analyses using Wilcoxon's test for paired observations'' (p. 5)
- also used Chi-squared test
- linear regression used to investigate effect of effect size and Impact Factor

RESULTS
CHARACTERISTICS OF INCLUDED STUDIES
- 663 meta-analyses, 66 cognitive or behavioral and 97 brain imaging
- all be two meta-analyses from psychiatry
DO INITIAL STUDIES AGREE WTIH SUBSEQUENT META-ANALYSES?
- sensitivity of initial studies from 0.58 to 0.64, similar across 3 biomedical domains
- specificity from 0.47 to 0.70, lower for psychiatry than neurology and somatic diseases
- in psychiatry not better than chance, but okay for other two
- looked at stringent meta-analyses (smaller p to disprove), within this subset sensitivity and specificity didn't change, similar results regarding psychiatry
DO INITIAL STUDIES REPORT INFLATED EFFECT SIZES?
- 59{\%} of initial studies had an effect size inflated by more than 50{\%}, over half of those inflated by more than 100{\%}
- largest studies much more consistent with meta-analyses than initial paper
ARE INITIAL STUDIES CONSISTENT WITH SUBSEQUENT META-ANALYSES?
- defined replication as matching significance and effect size not beyond either 50{\%} or 100{\%} of meta-analyses
- psychiatric disorders less often replicated
- no difference in replication rates between psychiatric disorders and somatic disorders
ARE HIGHLY SIGNIFICANT INITIAL STUDIES MORE RELIABLE?
- ``initial studies reporting a highly significant effect are no more reliable than those reporting a p-value between 0.05 and 0.005'' (p. 10)
DOES REPLICATION RATE OF INITIAL STUDIES DIFFER BY STUDY TYPE?
- ``Within psychiatry, initial studies of cognitive/behavioral associations exhibited the highest replication rate, whereas those regarding genetic associations were the least replicated.'' (p. 11)
- ``This analysis shows that initial studies in biological psychiatry were less reliable than those of both other biomedical domains.'' (p. 12)
DOES REPLICATION RATE DEPEND ON SAMPLE SIZE AND ``TRUE'' EFFECT SIZE?
- smallest replication rates when smaller effect size
ARE LARGEST STUDIES MORE RELIABLE?
- sensitivity of initial studies similar to large studies, but specificity better for large studies
- also true with more stringent meta-analyses
ARE STUDIES PUBLISHED IN HIGH IMPACT FACTOR JOURNALS MORE RELIABLE?
- no evidence of a correlation of impact factor and reliability of study except genetic studies in psychiatry, neurology, and ``other'' somatic diseases
DOES PUBLICATION YEAR INFLUENCE THE RELIABILITY?
- no evidence of effect of publication year
- for some reason impression that less often replicated (?)
ARE INITIAL STUDIES REPRESENTATIVE OF LATER STUDIES?
- ``For the eight subgroups, the sample size of initial studies was always smaller than for the averaged subsequent studies, but with noticeable differences.'' (p. 15)
- sample size tends to be larger for follow-up studies

COMMENTS
- results shows replication validity is low
- replication rate 6.3{\%} (genetic studies of psychiatric disorders) to 86.4{\%} (cognitive/behavioral studies of psychiatric disorders)
- small sample sizes leads to lack of reproducibility and inflated effect sizes
- no effect of journal Impact Factor on reliability of studies

LIMITATIONS
- publication bias likely to add to low replicability
- smaller p-values of original study more likely to be replicable
- ``Whether our sample of initial studies was representative regarding replication validity remains to be elucidated.'' (p. 17)

CONCLUSION
- replication numbers may be useful for when scientists talk to the media
- ``Initial findings should always be described as tentative, uncertain and requiring replication when reported in the scientific literature, the academic press releases and the media.'' (p. 18)},
	Author = {Dumas-Mallet, Estelle and Button, Katherine and Boraud, Thomas and Munafo, Marcus and Gonon, Fran{\c{c}}ois},
	Date-Added = {2016-07-26 14:59:19 +0000},
	Date-Modified = {2016-07-26 14:59:19 +0000},
	Doi = {10.1371/journal.pone.0158064},
	File = {:Users/pagepiccinini/Desktop/Literature/Already Read with Notes/Dumas-Mallet2016.PDF:PDF},
	Issn = {1932-6203},
	Journal = {Plos One},
	Number = {6},
	Pages = {e0158064},
	Title = {{Replication validity of initial association studies: A comparison between psychiatry, neurology and four somatic diseases}},
	Url = {http://dx.plos.org/10.1371/journal.pone.0158064},
	Volume = {11},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.plos.org/10.1371/journal.pone.0158064},
	Bdsk-Url-2 = {http://dx.doi.org/10.1371/journal.pone.0158064}}
