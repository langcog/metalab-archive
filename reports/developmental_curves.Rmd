---
title: "Developmental curve comparison"
author: "Page and Mike"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    highlight: tango
    toc: true
    number_sections: true
    code_folding: hide
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width = 8, fig.height = 5, echo = TRUE,
                      warning = FALSE, message = FALSE, cache = TRUE)
ggplot2::theme_set(langcog::theme_mikabr(base_family = "Ubuntu"))
source("../dashboard/global.R", chdir = TRUE)
```

```{r, echo=FALSE, cache=FALSE}
library(ggplot2)
library(broom)
library(dplyr)
library(tidyr)
library(lme4)
library(metafor)
```

```{r}
xtabs(~dataset, all_data)
```

# Introduction

The goal for this analysis was to better understand the shape of the developmental curve. To do this we examined both general curves across all data sets and curves taking into account data set specific variance.

Summary of investigations:

* Running regressions over the entire data set is not appropriate.
* Looked at meta-analytic mixed effects - this approach is promising, but...
* The random effects structure (specifically if we nest paper effects within dataset effects) makes a big difference to the implied curve shape. 

# Plots

First look at the whole data set with various model types: 1) linear, 2) log, 3) quadratic, and 4) loess.

```{r, fig.align = 'center', echo=FALSE}
ggplot(all_data, aes(x = mean_age, y = d)) +
  geom_point(col = "black", aes(size = n)) + 
  geom_smooth(method="lm", formula = y ~ x, aes(col = "Linear"), 
              se = FALSE) + 
  geom_smooth(method="lm", formula = y ~ I(x^2), aes(col = "Quadratic"), 
              se = FALSE) + 
  geom_smooth(method="lm", formula = y ~ log(x), aes(col = "Log"), 
              se = FALSE) + 
  geom_smooth(method="loess", span = 1, aes(col = "Loess"), 
              se = FALSE) + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  scale_colour_manual(name="Models", breaks=c("Linear", "Log", "Quadratic", "Loess"),
                          values=c("Linear"="red",
                                              "Quadratic"="blue",
                                              "Log"="green",
                                              "Loess"="orange"))
```

Next, we examine the curves for each plot data set sepatately. 

```{r, fig.align='center', echo=FALSE}
# Removed "size = n" for all attributes of plot because with it the regression lines
# didn't show up on most of the plots.
ggplot(all_data, aes(x = mean_age, y = d)) +
  geom_point(aes(size = n)) + 
  geom_smooth(method="lm", formula = y ~ x, aes(col = "Linear"), 
              se = FALSE) + 
  geom_smooth(method="lm", formula = y ~ I(x^2), aes(col = "Quadratic"), 
              se = FALSE) + 
  geom_smooth(method="lm", formula = y ~ log(x), aes(col = "Log"), 
              se = FALSE) + 
  geom_smooth(method="loess", span = 1, aes(col = "Loess"), 
              se = FALSE) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  scale_colour_manual(name="Models", breaks=c("Linear", "Log", "Quadratic", "Loess"),
                      values=c("Linear"="red",
                                              "Quadratic"="blue",
                                              "Log"="green",
                                              "Loess"="orange"))

```


# Simple Regressions

To see if one particular type of model is a better fit of the data, we run each model and the compare them with an ANOVA.

```{r}
lin_mod <- lm(d ~ mean_age, weights = 1/d_var, data = all_data)
log_mod <- lm(d ~ log(mean_age), weights = 1/d_var, data = all_data)
quad_mod <- lm(d ~ I(mean_age^2), weights = 1/d_var, data = all_data)
```

Examine each model and look at head to head comparisions.

```{r}
summary(lin_mod)
summary(log_mod)
summary(quad_mod)

anova(lin_mod, log_mod)
anova(lin_mod, quad_mod)
anova(log_mod, quad_mod)
```

We also built and compared models with single predictors to those with multiple predictors.

```{r}
lin_log_mod <- lm(d ~ mean_age + log(mean_age), 
                  weights = 1/d_var, 
                  data = all_data)
summary(lin_log_mod)

anova(lin_mod, lin_log_mod)
anova(log_mod, lin_log_mod)
```

Let's look at what that graph looks like on a plot. 

```{r, fig.align='center', echo=FALSE}
ggplot(all_data, 
       aes(x = mean_age, y = d)) + 
  geom_point(aes(size = 1/d_var)) + 
  geom_smooth(method = "lm", formula = y ~ x + log(x), 
              se = FALSE, aes(col = "Linear")) +   
  geom_smooth(method = "lm", formula = y ~ x, 
              se = FALSE, aes(col = "Quadratic")) +
  geom_smooth(method = "lm", formula = y ~ log(x), 
              se = FALSE, aes(col = "Log")) + 
  scale_colour_manual(name="Models", values=c("Linear"="red",
                                              "Quadratic"="blue",
                                              "Log"="green"))

```

This tells us that modeling the whole dataset doesn't make sense. 

# Mixed-effects regression

[A very informative post on the difference between `rma` and `lm`/`lmer`](http://www.metafor-project.org/doku.php/tips:rma_vs_lm_and_lme) suggests that we want to do random effects MA in `lme` by setting `control=lmeControl(sigma = 1)`. But we can't do that under `lme4`. There's [a branch of lme4](https://github.com/lme4/lme4/issues/224) that deals with this, but it looks pretty intense. 

So we'll eat this issue for now but note that we may want to go back and do this using metafor. 

## Simple mixed-effects

As a second step ran mixed effects regressions where data set was included as a random intercept.

```{r}
lin_lmer <- lmer(d ~ mean_age + 
                   (1 | dataset), 
                 weights = 1/d_var, 
                 data = all_data)
coef(summary(lin_lmer))              
```

```{r}
log_lmer <- lmer(d ~ log(mean_age) + 
                   (1 | dataset), 
                 weights = 1/d_var, 
                 data = all_data)
coef(summary(log_lmer))
```

```{r}
quad_lmer <- lmer(d ~ I(mean_age^2) + 
                   (1 | dataset), 
                 weights = 1/d_var, 
                 data = all_data)
coef(summary(quad_lmer))
```

and the joint, log+linear model 

```{r}
log_lin_lmer <- lmer(d ~ mean_age + log(mean_age) + 
                   (1| dataset), 
                 weights = 1/d_var, 
                 data = all_data)
coef(summary(log_lin_lmer))

```

ANOVA - hard to interpret?

```{r}
anova(lin_lmer, log_lmer)
anova(lin_lmer, log_lin_lmer)
```

Let's look at these. 

```{r, fig.align='center', echo=FALSE}
ggplot(all_data, aes(x = mean_age, y = d, 
                     weight = 1/d_var)) +
  geom_point(aes(size = 1/d_var)) + 
  geom_smooth(method="lm", formula = y ~ x, 
              aes(col = "Linear"), 
              se = FALSE) + 
  geom_smooth(method="lm", formula = y ~ log(x), 
              aes(col = "Log"),
              se = FALSE) + 
  geom_smooth(method="lm", formula = y ~ I(x^2),
              aes(col = "Quadratic"),
              se = FALSE) +
  geom_smooth(method="lm", formula = y ~ x + log(x), 
              aes(col = "Log+Linear"),
              se = FALSE) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  scale_colour_manual(name="Models", values=c("Linear"="red",
                                              "Log"="blue",
                                              "Quadratic" = "purple",
                                              "Log+Linear"="green"))

```

Now try to plot actual model. 

```{r, fig.align='center', echo =FALSE}
all_data_preds <- all_data %>%
  select(dataset, d, d_var, mean_age, unique_ID) %>%
  filter(complete.cases(.)) %>%
  mutate(log_lin_pred = predict(log_lin_lmer))

ggplot(all_data_preds, aes(x = mean_age, y = d, 
                     weight = 1/d_var)) +
  geom_point(aes(size = 1/d_var)) + 
  geom_line(aes(x = mean_age, y = log_lin_pred, size = 1, col = "Log+Linear")) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  scale_colour_manual(name="Models", values=c("Log+Linear"="red"))

```

Summary - this looks pretty good, seems like the linear model is somehow smoothing the logs at the edges, and the random effects are working to capture cross-dataset variability. 

## Mixed effects with nested paper effects

Next add nested paper effects? 

```{r}
log_lin_paper_lmer <- lmer(d ~ mean_age + log(mean_age) + 
                             (1 | dataset / unique_ID),
                           weights = 1/d_var, 
                           data = all_data)
coef(summary(log_lin_paper_lmer))

#anova(log_lin_paper_lmer, log_lin_paper_int_lmer)
```

Summary: these models capture more variance, especially the nested slopes one.

We now predict from this model, attempting to remove the nested paper effect (set to zero for generalization). Blue is the new model. 

```{r, fig.align='center', echo=FALSE}
preds <- predict(log_lin_paper_lmer, re.form = ~ (1 | dataset / unique_ID))
all_data_preds <- all_data_preds %>%
  mutate(log_lin_paper_pred = preds)

ggplot(all_data_preds, aes(x = mean_age, y = d, 
                     weight = 1/d_var)) +
  geom_point(aes(size = 1/d_var)) + 
  geom_line(aes(x = mean_age, y = log_lin_pred, size = 1, col = "Log+Linear")) + 
  geom_line(aes(x = mean_age, y = log_lin_paper_pred, size = 1, 
                col = "Paper Random Effect")) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") +
  scale_colour_manual(name="Models", values=c("Log+Linear"="red","Paper Random Effect"="blue"))

```

People test babies of the same age, so you may be gettting massive overfitting of individual age groups. But we don't see big differences in the models (aside from loss of significance on predictors).

## Subset to only those papers with multiple ages

Let's check whether we can feel better about the overfitting issue by subsetting to papers with more than one age, so we are getting better confidence on the random slope. 

### Two age groups. 

We arbitrarily decide on two age groups, more than 2mo apart. 

```{r}
multiage_data <- all_data_preds %>%
  group_by(dataset, unique_ID) %>%
  mutate(count_ages = length(unique(floor(mean_age/2)))) %>%
  filter(count_ages > 1)

nested_multiage_lmer <- lmer(d ~ mean_age + log(mean_age) + 
                             (log(mean_age) | dataset / unique_ID),
                           weights = 1/d_var, 
                           data = multiage_data)
coef(summary(nested_multiage_lmer))
```

Wow - much better. 

Plot this. Again, blue is new.

```{r, fig.align='center', echo=FALSE}
preds <- predict(nested_multiage_lmer, re.form = ~ (log(mean_age) | dataset))

multiage_data <- multiage_data %>%
  ungroup %>%
  select(dataset, unique_ID, d, mean_age, d_var, log_lin_pred) %>%
  mutate(nested_pred = preds)

ggplot(multiage_data, aes(x = mean_age, y = d, 
                     weight = 1/d_var)) +
  geom_point(aes(size = 1/d_var)) + 
  geom_line(aes(x = mean_age, y = log_lin_pred, col = "Log+Linear")) + 
  geom_line(aes(x = mean_age, y = nested_pred,
                col = "Paper Random Effect")) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") +
  scale_colour_manual(name="Models", values=c("Log+Linear"="red","Paper Random Effect"="blue"))
```

### Three age groups

```{r, fig.align='center', echo=FALSE}
multiage_data <- all_data_preds %>%
  group_by(dataset, unique_ID) %>%
  mutate(count_ages = length(unique(floor(mean_age/2)))) %>%
  filter(count_ages > 2)

nested_multiage_lmer <- lmer(d ~ mean_age + log(mean_age) + 
                             (log(mean_age) | dataset / unique_ID),
                           weights = 1/d_var, 
                           data = multiage_data)
coef(summary(nested_multiage_lmer))

preds <- predict(nested_multiage_lmer, re.form = ~ (log(mean_age) | dataset))

multiage_data <- multiage_data %>%
  ungroup %>%
  select(dataset, unique_ID, d, mean_age, d_var, log_lin_pred) %>%
  mutate(nested_pred = preds)

ggplot(multiage_data, aes(x = mean_age, y = d, 
                     weight = 1/d_var)) +
  geom_point(aes(size = 1/d_var)) + 
  geom_line(aes(x = mean_age, y = log_lin_pred, col = "Log+Linear")) + 
  geom_line(aes(x = mean_age, y = nested_pred, 
                col = "Paper Random Effect")) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") +
  scale_colour_manual(name="Models", values=c("Log+Linear"="red",
                                              "Paper Random Effect"="blue"))
```

### Two age groups, no slope per paper

```{r, fig.align='center', echo=FALSE}
multiage_data <- all_data_preds %>%
  group_by(dataset, unique_ID) %>%
  mutate(count_ages = length(unique(floor(mean_age/2)))) %>%
  filter(count_ages > 1)

nested_multiage_lmer <- lmer(d ~ mean_age + log(mean_age) + 
                               (log(mean_age) | dataset) + 
                               (1 | unique_ID),
                           weights = 1/d_var, 
                           data = multiage_data)
coef(summary(nested_multiage_lmer))

preds <- predict(nested_multiage_lmer, re.form = ~ (log(mean_age) | dataset))

multiage_data <- multiage_data %>%
  ungroup %>%
  select(dataset, unique_ID, d, mean_age, d_var, log_lin_pred) %>%
  mutate(nested_pred = preds)

ggplot(multiage_data, aes(x = mean_age, y = d, 
                     weight = 1/d_var)) +
  geom_point(aes(size = 1/d_var)) + 
  geom_line(aes(x = mean_age, y = log_lin_pred, col = "Log+Linear")) + 
  geom_line(aes(x = mean_age, y = nested_pred, 
                col = "Paper Random Effect")) + 
  facet_wrap(~ dataset, scales = "free") + 
  geom_hline(yintercept = 0, lty = 2, col = "black") +
  scale_colour_manual(name="Models", values=c("Log+Linear"="red",
                                              "Paper Random Effect"="blue"))
```

Conclusion: Paper-level random effects make a really big difference here. Hard to know what to make of this. 


# Conclusions


