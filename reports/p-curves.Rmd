---
title: "P-Curves"
author: "Molly Lewis, Christina Bergmann, and Mike Frank"
date: "This report was rendered on `r Sys.Date()` and will be automatically re-rendered nightly, reflecting any changes in the data or code."
---

```{r, setup, include = FALSE}
rm(list=ls())
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = FALSE)
ggplot2::theme_set(langcog::theme_mikabr(base_family = "Ubuntu"))
source("../dashboard/global.R", chdir = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(langcog)
```

# Introduction

P-curves have been proposed as one (of many) ways to measure publication biases, because so-called p-hacking (conducting multiple statistical analyses, excluding data points, etc until a p-value below the significance threshold [typically .05] is reached) can lead to an inflation of high p-values that are nonetheless significant. The exected distribution of p-values in the absence of prevalent p-hacking of a null effect is biased towards smaller values. The present script is based on the p-curve app version 4.0.

One of the main problems with p-curve is the use of text mining to generate input, and the presence of heterogeneous tests (https://peerj.com/articles/1715/). In the case of MetaLab, however, all test statistics were entered by hand and concern a homogeneous research literature (within each dataset). Further, we only enter the *main* test statistic which would also be used to calculate effect sizes in our meta-analysis. Therefore, we believe that p-curve is an appropriate analysis for the dataset. 

### Data preparation

When reported or necessary to calculate effect sizes, we note the t-value or F-score for each record (a single study). We do not consider studies for which this information was unavailable in the following analyses. 

To calculate p-values from $t$-values and $F$-scores, we also need the degrees of freedom. When one group of participants was tested, we use $N-1$, for a two group comparison design we use $N-2$. $F$-scores require two degrees of freedom, the first one however is always one in the main analysis of interest (we do not enter or consider e.g., interactions of the main effect of interest with covariates such as age, gender, etc.).

We need to source code from the p-curve app. This p-curve report is based on the p-curve app 4.0 (accessed 25.02.2015) via code from the [app](http://p-curve.com/app4/App%204.0%20p-curve%202016%2001%2011.r). We have heavily adapted this code, however. 

```{r}
source("pcurve.R")
```

Set global variables
```{r}
ALPHA = .05
```

Get all data necessary to calculate p-curves
```{r PlotEachDataSet}
pc.data <- get_all_pc_data(all_data, ALPHA)
```

## P-curve for each individual dataset
```{r}
pc.data %>%
  group_by(dataset) %>%
  do(get_p_curve_df(., ALPHA)) %>%
  ggplot(aes(x = p, y = value, col = measure, lty = measure)) + 
  geom_line() +
  facet_wrap(~ dataset)
```

## Test for right skew.
```{r}
stouffer.data = pc.data %>%
  group_by(dataset) %>%
  do(data.frame(stouffer = stouffer_test(., ALPHA))) 
```

## Get p-curve power.
```{r}
pc.data %>%
  group_by(dataset) %>%
  do(data.frame(power = get_pc_power(., ALPHA))) 
```

## Get p-curves es estimates.
```{r}
pc.data %>%
  group_by(dataset) %>%
  do(data.frame(get_pc_es(., ALPHA))) 

# get mefafor es
#metafor::rma(rma_formula, vi = mod_data()[[es_var()]],
    #         slab = short_cite, data = mod_data(),
     #        method = input$ma_method)

# TO DO:
 # get metafor estimates of effect size
 # plot stuff
 # why are some datasets missing?
 # check code!!

```
