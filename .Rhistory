axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
```
c( -0.1976 ,1.0309     )-1
.41-1
pdf("/Users/mll/Desktop/vocab.pdf", width = 5, height =5)
ggplot(md, aes(x=log(CDI_prod_mean), y=d_calculate, label = num_lab))+
ylab("Cohen's d")+
xlab("Log CDI productive vocab.")+
#geom_smooth(method="lm", formula=y~log(x)) +
geom_smooth(method="lm", color = "steelblue",alpha = .3, size = 1.25) +
theme_bw() +
scale_y_continuous(limits = c(-1, 2.5)) +
theme(text = element_text(size=30),
plot.title=element_text(size=20, face = "bold"),
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
pdf("/Users/mll/Desktop/vocab.pdf", width = 5, height =5)
ggplot(md, aes(x=log(CDI_prod_mean), y=d_calculate, label = num_lab))+
ylab("Cohen's d")+
xlab("Log CDI prod. vocab.")+
#geom_smooth(method="lm", formula=y~log(x)) +
geom_smooth(method="lm", color = "steelblue",alpha = .3, size = 1.25) +
theme_bw() +
scale_y_continuous(limits = c(-1, 2.5)) +
theme(text = element_text(size=30),
plot.title=element_text(size=20, face = "bold"),
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
## Analysis #3: Vocab size as predictor
plot vocab as predictor of effect size with basic linear model
```{r}
pdf("/Users/mll/Desktop/vocab.pdf", width = 6, height =6)
ggplot(md, aes(x=log(CDI_prod_mean), y=d_calculate, label = num_lab))+
ylab("Cohen's d")+
xlab("Log CDI prod. vocab.")+
#geom_smooth(method="lm", formula=y~log(x)) +
geom_smooth(method="lm", color = "steelblue",alpha = .3, size = 1.25) +
theme_bw() +
scale_y_continuous(limits = c(-1, 2.5)) +
theme(text = element_text(size=30),
plot.title=element_text(size=20, face = "bold"),
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
```
## Analysis #3: Vocab size as predictor
plot vocab as predictor of effect size with basic linear model
```{r}
pdf("/Users/mll/Desktop/vocab.pdf", width = 6, height =6)
ggplot(md, aes(x=log(CDI_prod_mean), y=d_calculate, label = num_lab))+
ylab("Cohen's d")+
xlab("Log CDI productive. vocab.")+
#geom_smooth(method="lm", formula=y~log(x)) +
geom_smooth(method="lm", color = "steelblue",alpha = .3, size = 1.25) +
theme_bw() +
scale_y_continuous(limits = c(-1, 2.5)) +
theme(text = element_text(size=30),
plot.title=element_text(size=20, face = "bold"),
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
## Analysis #3: Vocab size as predictor
plot vocab as predictor of effect size with basic linear model
```{r}
pdf("/Users/mll/Desktop/vocab.pdf", width = 6, height =6)
ggplot(md, aes(x=log(CDI_prod_mean), y=d_calculate, label = num_lab))+
ylab("Cohen's d")+
xlab("Log CDI productive vocab.")+
#geom_smooth(method="lm", formula=y~log(x)) +
geom_smooth(method="lm", color = "steelblue",alpha = .3, size = 1.25) +
theme_bw() +
scale_y_continuous(limits = c(-1, 2.5)) +
theme(text = element_text(size=30),
plot.title=element_text(size=20, face = "bold"),
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
```
Now, compare BOTH age and vocab in random effect model
```{r}
md.good = md[!is.na(md$CDI_prod_mean),]
result.all.mods= rma(md.good$d_calculate ~ log(md.good$CDI_prod_mean) +
log(md.good$age_mean..months.), vi = md.good$d_var, method = "REML")
result.all.mods
```
m1 = lm(scale(d_calculate) ~ scale(log(CDI_prod_mean)) +
scale(log(age_mean..months.)), d=md)
summary(m1)
m1 = lm(scale(d_calculate) ~ scale(log(CDI_prod_mean)) +
scale(log(age_mean..months.)), d=md)
pdf("/Users/mll/Desktop/vocab.pdf", width = 6, height =6)
ggplot(md, aes(x=log(CDI_prod_mean), y=d_calculate, label = num_lab))+
ylab("Cohen's d")+
#xlab("Log CDI productive vocab.")+
xlab("Age as moderator")+
#geom_smooth(method="lm", formula=y~log(x)) +
geom_smooth(method="lm", color = "steelblue",alpha = .3, size = 1.25) +
theme_bw() +
scale_y_continuous(limits = c(-1, 2.5)) +
theme(text = element_text(size=30),
plot.title=element_text(size=20, face = "bold"),
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = 'black',size = 1.5),
axis.ticks = element_line(size = 1.5)) +
geom_text(fontface = 2, size = 6) +
annotate("text", x=5.5, y=-.5, size = 10,
label=paste("r=",round(cor(md$d_calculate, log(md$CDI_prod_mean), use = "complete"), 2)),
color="red")
cor.test(md$d_calculate, log(md$CDI_prod_mean), use = "complete.obs")
dev.off()
---
title: "Disambiguation Meta-Analysis"
output: html_document
---
```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```
load libraries and functions
```{r}
library(ggplot2)
library(metafor)
source("/Documents/GRADUATE_SCHOOL/Ranalysis/useful.R")
# calculate variance on d, assumes variance in (imaginery) control group same as experimental
d_var<- function(n, d){
vd = ((2*n)/(n^2)) + ((d^2)/(4*n))
return(vd)
}
```
load data
```{r}
metad = read.csv("/Documents/GRADUATE_SCHOOL/Projects/ME_meta/SRCD_abstract/data/Disambiguation Meta-Analysis Data.csv")
```
calculate d for conditions not reported
```{r}
metad$d_by_t <- metad$t/sqrt(metad$N)
metad$d_by_M <- (metad$M_experimental-metad$M_baseline) / metad$SD
```
get a d for each condition
```{r}
metad$d_calculate <- ifelse(!is.na(metad$d), metad$d,
ifelse(!is.na(metad$d_by_t),metad$d_by_t,
ifelse(!is.na(metad$d_by_M), metad$d_by_M, NA)))
```
```{r echo = FALSE, eval = F}
#look at rows with discrepant d's
metad$d_error = ifelse((abs(metad$d_by_t-metad$d_by_M )> .1) | (abs(metad$d-metad$d_by_M ) > .1) | (abs(metad$d-metad$d_by_t)> .1), 1, 0)
metad[which(metad$d_error == 1),c("paper_key","t","N","M_experimental", "M_baseline" ,"SD", "d", "d_by_t", "d_by_M")] # Diesendruck and demarchena
```
remove conditions for which we have no d or we're excluding for methodological reasons
```{r}
#metad[!is.na(metad$d_calculate),c("paper_key","t","N","M_experimental", "M_baseline" ,"SD", "d", "d_by_t", "d_by_M",'d_calculate', 'd_error')]
md <- metad[!is.na(metad$d_calculate),]
md <- md[md$include.in.basic.analysis.==1,]
md <- md[md$paper_key != "frank2015",]
# sanity check for indexing: which condition has the max
#md[which(md$d_calculate==(max(md$d_calculate, na.rm=T))),
#  c("paper_key", "d_calculate")]
#md.order = md[order(md$d_calculate),]
```
```{r, eval = F, echo =F}
# look at conditions we have d's for
#md$notes_short = substr(md$Notes,1,40)
#md[, c("paper_key", 'notes_short', "expt_num",'d_calculate', "N")]
#md <- md[order(md$paper_key),]
#md[order(md$d_calculate),c("paper_key", 'notes_short', "expt_num",'d_calculate')]  #sorted by effectsize
```
get var on d
```{r}
md$d_var = apply(md[,c('N','d_calculate')], 1, function(x) d_var(x[1],x[2]))
```
summary of final sample of studies
```{r}
# total number of unique studies
length(unique(metad$paper_key))
# number of unique studies usable
length(unique(md$paper_key))#21
# total number of conditions
dim(md)[1] #63
```
## Analysis #1: Effect size across studies
distribution of raw cohen's d's.
```{r}
qplot(d_calculate, data=md, geom="histogram") +
geom_vline(xintercept = 0, color = "red", cex = 2)
```
get random effect model
```{r}
result.all = rma(md$d_calculate, vi = md$d_var, method = "REML")
result.all
```
result.all
forest(result.all,
slab = md$lab,
ilab = cbind(md$year, md$age_mean..months.,
md$N, as.character(md$DV.type)),
ilab.xpos = c(-6.25,-5,-4,-3),
order = order(md$DV.type, md$age_mean..months.),
mlab = "Grand effect size",
xlab ="Effect size estimate",
xlim = c(-9, 2),
annotate = F)
forest(result.all,
#slab = md$lab,
ilab = cbind(md$year, md$age_mean..months.,
md$N, as.character(md$DV.type)),
ilab.xpos = c(-6.25,-5,-4,-3),
order = order(md$DV.type, md$age_mean..months.),
mlab = "Grand effect size",
xlab ="Effect size estimate",
xlim = c(-9, 2),
annotate = F)
text(-8, 54, "First author", po
225/836
m = 225/836
927*m
system('python /Documents/GRADUATE_SCHOOL/Misc./psiturk/sqltocsv.py')
system('python /Documents/GRADUATE_SCHOOL/Misc./psiturk/sqltocsv.py')
library(rPython)
install.packages(rPython)
install.packages('rPython')
library(rPackages)
library(rPython)
python.load('/Documents/GRADUATE_SCHOOL/Misc./psiturk/sqltocsv.py')
python.load('/Documents/GRADUATE_SCHOOL/Misc./psiturk/sqltocsv.py')
python.load('/Documents/GRADUATE_SCHOOL/Misc./psiturk/sqltocsv.py')
python.load('/Documents/GRADUATE_SCHOOL/Misc./psiturk/sqltocsv.py')
runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz')
library(shiny)
runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz')
runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz')
shiny::runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz')
data <- function() {
read.csv(paste0('data/', input$dataset, '.csv')) %>%
map_fields(input$dataset, .) %>%
filter(!is.na(effect_size)) %>%
select(method, effect_size, n, mean_age)
}
d<- data.frame(
groupname = as.factor(sample(c("red", "green", "blue"), 100, replace = TRUE)),
timeblock = sample(1:10, 100, replace = TRUE),
someuser = sample(c("bob", "sally", "sue"), 100, replace = TRUE))
d
table(d$someuser)
freq(d$someuser)
summary(d)
freq(d$someuser)[1]
table(d$someuser)[1]
table(d$someuser)[1,1]
count(d$someuser)
?count
tally(d$someuser, yearID)
tally(d$someuser)
batting_tbl <- tbl_df(Batting)
tally(group_by(batting_tbl, yearID))
tally(group_by(batting_tbl, yearID), sort = TRUE)
library(dplyr)
batting_tbl <- tbl_df(Batting)
?tally
d %>% count (someuser)
d %>% count (someuser, sort = T)
d %>% count (someuser, sort = T)[1]
k = d %>% count (someuser, sort = T)
k
k[1]
k[2,1]
k[1,1]
k = d %>% count (someuser, sort = T) [1,1]
summary(d)
k[1,1]
k = d %>%
count (someuser, sort = T)  %>%
select(someuser)
k
k = d %>%
count (someuser, sort = T)  %>%
select(someuser[1])
k
k = d %>%
count (someuser, sort = T)  %>%
select(someuser[,1])
d %>%
count (someuser, sort = T)  %>%
select(someuser)
d %>%
count (someuser, sort = T)  %>%
select(someuser) %>%
as.data.frame(d)[1,1]
d %>%
count (someuser, sort = T)  %>%
select(someuser) %>%
as.data.frame()
d %>%
count (someuser, sort = T)  %>%
select(someuser) %>%
as.data.frame()[1]
d %>%
count (someuser, sort = T)  %>%
select(someuser) %>%
as.data.frame() %>%
[1]
k = d %>%
count (someuser, sort = T)  %>%
select(someuser) %>%
as.data.frame()
k
k = d %>%
count (someuser, sort = T)  %>%
select(someuser) %>%
as.data.frame() [1]
m = d %>%
count (someuser, sort = T)  %>%
select(someuser)
m
m[1]
m[1,1]
m
m = count (d, someuser, sort = T)
m
m[1,1]
m = count (d, column_name, sort = T)
m[1,1]
m[2,1]
summary(d)
?mode
mode(d$timeblock)
temp <- table(as.factor(d$someuser))
names(temp)[temp == max(temp)]
m[1,1]
tb = table(df$col)
names(tb)[tb== max(tb)]
tb = table(d$someuser)
names(tb)[tb== max(tb)]
tb
tb = table(d$someuser)
names(tb)[tb== max(tb)]
head(d)
?summarise
mode <- function (d) {
tb = table(d$someuser)
mode = names(tb)[tb== max(tb)]
return(mode)
}
d %>% group_by(groupname) %>% summarise(mode)
mode <- function (d) {
tb = table(d)
mode = names(tb)[tb== max(tb)]
return(mode)}
mode <- function (d) {
tb = table(d)
mode = names(tb)[tb== max(tb)]
return(mode)}
d %>% group_by(groupname) %>% summarise(someuser)
mode
mode(d$someuser)
summarise(group_by(groupname), mode = mean(someuser))
summarise(d,group_by(groupname), mode = mean(someuser))
summarise(group_by(d$groupname), mode = mean(d$someuser))
summarise(group_by(d,groupname), mode = mean(someuser))
summarise(group_by(d,groupname), mode = mode(someuser))
head(d)
t = head(d)
t
summarise(group_by(t,groupname), mode = mode(someuser))
mode
library (nycflights13)
install.packages(nycflights13)
install.packages('nycflights13')
df
library (nycflights13)
dim(flights)
head(flights)
flights
df
d
tbl_df(d)
?tbl_df
filter(d, month == 1)
filter(flights, month == 1)
filter(flights, dep_delay <-2)
filter(flights, dep_delay < -2)
slice(flights, 1:20)
arrange(flights, year, month, day)
glipse(d)
glimpse(d)
view(d)
View(d)
---
title: "Disambiguation Meta-Analysis"
output: html_document
---
```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```
load libraries and functions
```{r}
library(ggplot2)
library(metafor)
source("/Documents/GRADUATE_SCHOOL/Ranalysis/useful.R")
# calculate variance on d, assumes variance in (imaginery) control group same as experimental
d_var<- function(n, d){
vd = ((2*n)/(n^2)) + ((d^2)/(4*n))
return(vd)
}
```
load data
```{r}
metad = read.csv("/Documents/GRADUATE_SCHOOL/Projects/ME_meta/SRCD_abstract/data/Disambiguation Meta-Analysis Data.csv")
```
calculate d for conditions not reported
```{r}
metad$d_by_t <- metad$t/sqrt(metad$N)
metad$d_by_M <- (metad$M_experimental-metad$M_baseline) / metad$SD
```
get a d for each condition
```{r}
metad$d_calculate <- ifelse(!is.na(metad$d), metad$d,
ifelse(!is.na(metad$d_by_t),metad$d_by_t,
ifelse(!is.na(metad$d_by_M), metad$d_by_M, NA)))
```
```{r echo = FALSE, eval = F}
#look at rows with discrepant d's
metad$d_error = ifelse((abs(metad$d_by_t-metad$d_by_M )> .1) | (abs(metad$d-metad$d_by_M ) > .1) | (abs(metad$d-metad$d_by_t)> .1), 1, 0)
metad[which(metad$d_error == 1),c("paper_key","t","N","M_experimental", "M_baseline" ,"SD", "d", "d_by_t", "d_by_M")] # Diesendruck and demarchena
```
remove conditions for which we have no d or we're excluding for methodological reasons
```{r}
#metad[!is.na(metad$d_calculate),c("paper_key","t","N","M_experimental", "M_baseline" ,"SD", "d", "d_by_t", "d_by_M",'d_calculate', 'd_error')]
md <- metad[!is.na(metad$d_calculate),]
md <- md[md$include.in.basic.analysis.==1,]
md <- md[md$paper_key != "frank2015",]
# sanity check for indexing: which condition has the max
#md[which(md$d_calculate==(max(md$d_calculate, na.rm=T))),
#  c("paper_key", "d_calculate")]
#md.order = md[order(md$d_calculate),]
```
```{r, eval = F, echo =F}
# look at conditions we have d's for
#md$notes_short = substr(md$Notes,1,40)
#md[, c("paper_key", 'notes_short', "expt_num",'d_calculate', "N")]
#md <- md[order(md$paper_key),]
#md[order(md$d_calculate),c("paper_key", 'notes_short', "expt_num",'d_calculate')]  #sorted by effectsize
```
get var on d
```{r}
md$d_var = apply(md[,c('N','d_calculate')], 1, function(x) d_var(x[1],x[2]))
```
head(md)
write.csv("mutual_exclusivity.csv")
write.csv("mutual_exclusivity.csv",md)
write.csv(md,"mutual_exclusivity.csv")
runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz')
runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz/')
runApp('/Documents/GRADUATE_SCHOOL/Projects/ME_meta/metaviz/')
